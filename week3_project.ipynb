{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fb1ec90",
   "metadata": {},
   "source": [
    "> 1. DUPLICATE THIS COLAB TO START WORKING ON IT. Using File > Save a copy to drive.\n",
    "> 2. SET THE \"General Access\" OF THE COPIED NOTEBOOK TO \"Anyone with the link\" BY CLICKING ON \"Share\" TO ENABLE SHARING WITH YOUR PEERS FOR REVIEW.\n",
    "> 3. Download the data from the course and \"mount it\" (see cell below) so that you can work with it in this notebook\n",
    "\n",
    "\n",
    "### This project is from the *Causal Inference for Data Science course on CoRise.* Learn more about the course [here](https://corise.com/course/causal-inference-for-data-science).\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25666ca",
   "metadata": {},
   "source": [
    "# Week 3 Project: Applying Difference-in-Differences\n",
    "***\n",
    "\n",
    "Welcome to the third project for Causal Inference for Data Science!\n",
    "\n",
    "This project marks the end of our core curriculum. After this week, we'll take a brief tour of advanced methods by relating them to the ones you've already learned. We'll also work on a final \"wrap-up\" project that you can add to your data science portfolio.\n",
    "\n",
    "But we're getting ahead of ourselves: We still need to complete Week 3 :)\n",
    "\n",
    "\n",
    "## Scenario\n",
    "\n",
    "Your previous analyses have gone viral within Tongass. Suddenly, everyone is talking about the \"dynamic synergies\" between in-store and online sales.\n",
    "\n",
    "Pretty soon, you get a call from the CEO. \"I'm blown away,\" she says.\n",
    "\n",
    "\"Uh, thanks,\" you say, trying to keep it cool.\n",
    "\n",
    "\"I'm *so* blown away that I've decided to launch new physical locations in the tri-state area. Customers in New Jersey, New York, and Connecticut will have way more options going forward!\"\n",
    "\n",
    "\"Wow!\" you reply. \"That's amazing.\"\n",
    "\n",
    "\"Indeed, but I want to make sure we approach this launch thoughtfully before we expand to other geos. Could you analyze the impact of opening new stores in these states?\"\n",
    "\n",
    "\"Of course!\" you say. \"I'll make sure we have a solid causal inference plan and get a rigorous read on how these openings affect Tongass's business.\"\n",
    "\n",
    "\"Causal inference what now?\"\n",
    "\n",
    "\"Sorry,\" you reply. \"The point is: We're going to show Amazon who's boss.\"\n",
    "\n",
    "\"Excellent!\" she says.\n",
    "\n",
    "\n",
    "## Project notes\n",
    "\n",
    "As always, we start with the same notes:\n",
    "\n",
    "### Data\n",
    "\n",
    "We will work with a consistent data set througout this course (we introduce the data set more fully below). Not all parts of the data set will be applicable in any given week. The goal is demonstrating how a single set of granular data can be transformed to apply different causal inference techniques. We also hope to convey that manipulating data is in many ways the most important aspect of statistical modeling.\n",
    "\n",
    "### Structure\n",
    "\n",
    "We attempt to strike a balance between providing concrete steps to follow and making room for exploration. That said, we encourage you to explore: The best way to become a causal inference expert is to attack a single problem from multiple angles to see how different modeling choices affect an analysis. If this freedom is overwhelming, **don't panic**! You can simply fill out the code blocks marked \"TODO\" and ignore the optional ones. When we ask you to build models, we will provide the treatment effect you should expect so you can check your work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "143e4fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading necessary packages\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5bf162",
   "metadata": {},
   "source": [
    "## I. Load the data\n",
    "***\n",
    "\n",
    "We will work with a consistent data set throughout this course. The data set is in the file called `tongass_transactions.csv`.\n",
    "\n",
    "Note: The data set is at the **transaction level**, not the customer level. Any given customer can (and likely does) have multiple transactions. Some measures and fields are at the customer level, while others are at the transaction level. It will be up to you to manipulate this data set so that it can be used for analysis. As we'll discuss, this week's problem can be tackled at different levels of aggregation (e.g., individuals, states, treatment v. control groups). We'll need to be thoughtful about how to aggregate our data.\n",
    "\n",
    "Below, we define the fields that are relevant for this week:\n",
    "- `customer_id`: the unique identifier for a given customer\n",
    "- `age`: the age of the customer\n",
    "- `income`: the income of the customer \n",
    "- `state`: the customer's state of residence\n",
    "- `distance`: the distance (in miles) from a customer's home to the nearest Tongass store\n",
    "- `tx_order`: whether the transaction is the customer's first, second, third... etc.\n",
    "- `amount`: the dollar value of the transaction\n",
    "- `tx_date`: the date of the transaction\n",
    "- `is_credit`: whether the transaction involved a credit card or a different payment method (1 if credit card, 0 if other)\n",
    "- `in_store`: whether the transaction happened in a physical store (1 if yes, 0 if no and happened on tongass.com)\n",
    "\n",
    "**NOTE**: If we don't mention a field above, then it won't be relevant for this week :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32524d3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>state</th>\n",
       "      <th>received_re</th>\n",
       "      <th>received_in_store_re</th>\n",
       "      <th>distance</th>\n",
       "      <th>index</th>\n",
       "      <th>tx_order</th>\n",
       "      <th>amount</th>\n",
       "      <th>in_store</th>\n",
       "      <th>tx_date</th>\n",
       "      <th>is_credit</th>\n",
       "      <th>is_bonus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>122753</td>\n",
       "      <td>ND</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.765402</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.964375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>122753</td>\n",
       "      <td>ND</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.765402</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41.057234</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021-03-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>122753</td>\n",
       "      <td>ND</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.765402</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>71.752128</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2021-06-30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>122753</td>\n",
       "      <td>ND</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.765402</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>93.129942</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2022-10-31</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>79</td>\n",
       "      <td>32977</td>\n",
       "      <td>DC</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.146723</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.334116</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id  age  income state  received_re  received_in_store_re  \\\n",
       "0            0   65  122753    ND            0                     0   \n",
       "1            0   65  122753    ND            0                     0   \n",
       "2            0   65  122753    ND            0                     0   \n",
       "3            0   65  122753    ND            0                     0   \n",
       "4            1   79   32977    DC            0                     0   \n",
       "\n",
       "   distance  index  tx_order     amount  in_store     tx_date  is_credit  \\\n",
       "0  6.765402      0       0.0  61.964375       0.0  2020-12-31        0.0   \n",
       "1  6.765402      1       1.0  41.057234       0.0  2021-03-31        0.0   \n",
       "2  6.765402      2       2.0  71.752128       1.0  2021-06-30        1.0   \n",
       "3  6.765402      3       3.0  93.129942       1.0  2022-10-31        1.0   \n",
       "4  3.146723      0       0.0  61.334116       0.0  2020-01-31        0.0   \n",
       "\n",
       "   is_bonus  \n",
       "0       0.0  \n",
       "1       0.0  \n",
       "2       0.0  \n",
       "3       0.0  \n",
       "4       0.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: read in data (already filled out for you :)\n",
    "df = pd.read_csv('./tongass_transactions.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f656a4",
   "metadata": {},
   "source": [
    "## II. Modify the data set to prepare it for difference-in-differences analysis\n",
    "***\n",
    "\n",
    "In previous weeks, we got familiar with the data set. (If we hadn't, we would recommend repeating that step from Week 1!)\n",
    "\n",
    "Now, we want to approach our data through the lens of difference-in-differences specifically.\n",
    "\n",
    "First, that means adding in \"treatment\" and \"time period\" variables. Let's do that below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f17b806",
   "metadata": {},
   "outputs": [],
   "source": [
    "treated_states = ['NJ', 'NY', 'CT'] # stores open in these states\n",
    "store_opening_date = '2021-03-31' # stores open during this month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f86eeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: use the \"treated_states\" list to create a column for whether\n",
    "# an observation is in treatment group; use the \"store_opening_date\" variable\n",
    "# to create a column for whether an observation happens after treatment begins. keep in mind\n",
    "# that using 1s and 0s is more convenient than \"True\"s and \"False\"s when it comes to\n",
    "# fitting linear regressions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc796b7",
   "metadata": {},
   "source": [
    "## III. Aggregate the data set to the appropriate \"level\" and vet the parallel trends assumption; this also helps us see if our causal question is worth answering (spoiler: it will be)\n",
    "***\n",
    "\n",
    "As you know, difference-in-differences analysis hinges on a critical assumption known as \"parallel trends\" — that is, in the absence of the treatment, the treatment group would have seen the same trends as the control group.\n",
    "\n",
    "Unfortunately, we can never be 100% confident in parallel trends; however, we can at least gain some comfort with it.\n",
    "\n",
    "One way is by comparing the treatment and control groups visually to see whether they follow parallel trends prior to treatment. Try this now.\n",
    "\n",
    "The [seaborn lineplot function](https://seaborn.pydata.org/generated/seaborn.lineplot.html) is particularly helpful here.\n",
    "\n",
    "**Keep in mind that we could do this analysis at multiple \"levels\"**: in particular, we could visualize and model the effect of treatment on individual customers, states, or treatment/control groups overall. Similarly, we could aggregate the data to the month level or simply to the \"pre/post\" level. For this project, we'll aggregate the data to the \"state\" and \"month\" level, but there is no right answer here. Indeed, we'd encourage you to experiment with different levels of analysis to see how that changes your modeling process, but we'll leave that to the optional section below ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36c9abbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: aggregate data to state/month level and visualize treatment versus control for parallel trends"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf780ea9",
   "metadata": {},
   "source": [
    "## IV. Fit difference-in-differences model and interpret the results\n",
    "***\n",
    "\n",
    "Woohoo! It's finally time to start modeling. Fit a DD regression using state and month as controls (similar to how we fit a DD regression using farm and month as controls in this week's material)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c634a92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: fit a difference-in-differences model and interpret the results\n",
    "\n",
    "# CHECK: depending on how you aggregate your data and which additional controls you include, your\n",
    "# treatment effect should be ~329 (with a 95% CI of 48 to 610)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af289a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: convert this to a markdown cell and write a quick explanation of your model's results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ca3731",
   "metadata": {},
   "source": [
    "## V. Cluster your standard errors\n",
    "***\n",
    "\n",
    "Given how we chose to aggregate our data, we should cluster our standard errors to see if that changes the precision of our estimated treatment effect.\n",
    "\n",
    "Indeed, regardless of whether we fit our model at the customer- or state-level, it's common to cluster standard errors at the level of treatment (in this case, \"state\" is the level of treatment). It's also reasonable to try to-way clustering (e.g., at the state- _and_ month-level), although we don't need to worry about that for now.\n",
    "\n",
    "The key thing to remember about clustering is that it helps us account for subtle correlations between observations. Even if we account for state-level effects by including `state` in our model, our within-state error terms could still be correlated (e.g., if the economy in one or two states randomly booms, it might encourage shoppers in that state to spend more).\n",
    "\n",
    "Unfortunately, there is no \"one-size fits-all\" guidance about how to cluster your standard errors. (If you want a ton of detail, [this](https://cameron.econ.ucdavis.edu/research/Cameron_Miller_JHR_2015_February.pdf) is an excellent resource.) We personally like to try different justifiable clustering strategies and pick the most conservative (i.e., least precise)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f17cf4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: cluster your standard errors at the state-level\n",
    "# CHECK: Your clustered standard errors should actually be lower than the\n",
    "# unclustered versions — but remember: that can happen!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8b7e13d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: pick the version that you feel most confident in"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e594ce9",
   "metadata": {},
   "source": [
    "## VI. Tease out the causal mechanism by considering different outcome variables\n",
    "***\n",
    "\n",
    "In your analysis above, you likely use `amount` as your dependent variable. But there are other possible dependent variables we could consider, e.g., in-store sales or online sales.\n",
    "\n",
    "Try repeating your model-fitting process with these dependent variables.\n",
    "\n",
    "These complementary models help us determine whether opening new stores **only** boosts in-store sales, or whether overall sales increase but at the expense of online sales. Although overall sales is probably most important from a business standpoint, it's still important to understand _why_ a treatment works. We don't want people to think there are \"dynamic synergies\" between online and physical stores when, in reality, physical stores simply encourage customers to ignore the website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7dc8604f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: fit a version of your final model with \"in-store sales\" as your outcome variable\n",
    "\n",
    "# CHECK: depending on how you aggregate your data and which additional controls you include, your\n",
    "# treatment effect should be ~1955"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e42a979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: fit a version of your final model with \"online sales\" as your outcome variable\n",
    "\n",
    "# CHECK: depending on how you aggregate your data and which additional controls you include, your\n",
    "# treatment effect should be ~1612"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc133124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: convert this cell to a markdown cell and comment on what this means\n",
    "# for the causal mechanism we're analyzing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2a52f4",
   "metadata": {},
   "source": [
    "## VII. Consolidate the analysis you performed above so it's useful for a stakeholder\n",
    "***\n",
    "\n",
    "### Congratulations!\n",
    "\n",
    "You've done a ton of incredible work. Now, it's time to package it all together so the Tongas CEO can follow along.\n",
    "\n",
    "We will annoyingly repeat the same advice from previous weeks:\n",
    "\n",
    "This step often feels like doing an analysis \"in reverse.\" We don't want to step someone through all the logic we just went through to arrive at our answer (as tempting as that might be). We want to share our answer **first,** then help our stakeholders understand it intuitively by sharing visuals and explaining how confident we can be.\n",
    "\n",
    "Here is a set of suggested steps, but feel free to tweak as you see fit:\n",
    "- Share the results from your final model, making sure to put the results in **business terms** (e.g., \"opening stores in the tri-state area increased online sales by X and total sales by Y. Assuming stores cost less than Z to operate, or we can continue to increase revenues, we should do this in more states\")\n",
    "- Show key visuals to help someone grok the relationship intuitively\n",
    "- Comment on our degree of confidence of results, both in quantitative terms (e.g., confidence interval) and qualitative terms (e.g., \"model seems robust/sensitive to controls, which means we can be confident/should consider this a preliminary hypothesis warranting deeper experimentation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d83e986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: change this cell to a markdown cell and write an \"executive summary\" that\n",
    "# explains your results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8df8a40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: output a key visual (either from above or a new one) that you think communicates\n",
    "# your results in a statistically responsible way (tip: the same visual you used for parallel\n",
    "# trends might be helpful here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f6bc256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: change this cell to a markdown cell and write a blurb on how confident you\n",
    "# are in your results and why"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0e469b",
   "metadata": {},
   "source": [
    "## VIII. OPTIONAL: Consider additional analysis steps\n",
    "***\n",
    "1. We didn't ask for this explicitly, but it's possible to include additional controls in our difference-in-difference models to improve the precision of our estimates. For example, we might want to include additional \"state-level\" variables (e.g., average age of state, average distance of customers in state, etc.) to ensure we account for such differences between states. Consider fitting additional models with these kinds of controls.\n",
    "2. We would highly recommend tackling this problem in multiple ways to see how it changes your analysis. For example, you could try aggregating to an even higher level (just treatment v. control groups, just pre v. post time periods) to see and whether that changes your estimated treatment effect. Conversely, it's possible to go the other way and repeat this analysis at the individual _customer_ level. How would that analysis look? What causal question would that analysis be answering? (Note: This gets complicated, and we didn't want to get into all the nuances of panel data methods — that's a broader set of problems than difference-in-differences! That said, if you're interested, consider doing some reading about modeling individual panel data where observations are clustered into higher-level units (in this case, states) and tackling it again). You have all the foundational tools you need to take this on!\n",
    "3. The [`linearmodels`](https://bashtage.github.io/linearmodels/index.html) package in Python is made for working with panel data (e.g., it doesn't include every single state and month in your regression summary ;). Consider fitting models in this package so you have another tool in your DS arsenal.\n",
    "4. An important robustness check in some DD models is allowing variable time trends. As mentioned in the written material for this week, differential time trends allow for the possibility that treatment and control groups were following different (non-parallel ;) trends prior to treatment. Consider fitting another model with variable time trends as a robustness check. (TBH, this is mostly so you have practice — we can see from the parallel trends visualization that we don't need to worry about differential time trends.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c8bcc3",
   "metadata": {},
   "source": [
    "## IX. EXTREMELY OPTIONAL: Tackle another problem\n",
    "***\n",
    "\n",
    "When it comes to learning causal inference, there is no substitute for practice. We would strongly support finding data sets in the wild (e.g. [here](https://docs.google.com/spreadsheets/d/1wZhPLMCHKJvwOkP4juclhjFgqIY8fQFMemwKL2c64vk/edit#gid=0), [here](https://ourworldindata.org/), or [here](https://github.com/awesomedata/awesome-public-datasets) and using the same general framework we leveraged here toward a causal question you're interested in."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
